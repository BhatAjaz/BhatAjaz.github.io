<!DOCTYPE html>
<html>
    <head>
        <meta charset="utf-8">
<meta content="IE=edge,chrome=1" http-equiv="X-UA-Compatible">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="description" content="The UBD Ajaz Ahmad Bhat's lab is a multidisciplinary research hub focused on exploring the frontiers of artificial intelligence through the lens of human cognition and behavior. We build autonomous systems that think, reason, and adapt in ways that mirror—and often surpass—human intelligence.">
<title>Laboratory</title>
<link rel="canonical" href="http://0.0.0.0:5000/">
<link rel="icon" type="image/x-icon" href="/favicon.ico">
<link rel="shortcut icon" type="image/x-icon" href="/favicon.ico">
<link rel="stylesheet" type="text/css" href="/assets/css/styles.css">
    </head>
    <body>
        <!-- Navigation -->
<div class="background"> </div>
<nav class="nav-wrap">
    <a href="/" class="nav-logo">
    <?xml version="1.0" encoding="utf-8"?>
<svg version="1.1" id="Layer_1" xmlns="https://www.w3.org/2000/svg" xmlns:xlink="https://www.w3.org/1999/xlink" x="0px" y="0px"
     viewBox="0 0 403 230" style="enable-background:new 0 0 403 230;" xml:space="preserve">
  <g>
    <text x="50" y="150" font-family="Arial" font-size="100">AB LAB</text>
  </g>
</svg>
  </a>
  <ul class="navigation">
    <li><a href="/">Home</a></li>
    <li><a href="/team">Team</a></li>
    <li><a href="/publications">Publications</a></li>
    <li><a href="/projects">Projects</a></li>
    <li><a href="/news"> News</a></li>
    <li><a href="/contact-us">Contact</a></li>
  </ul>
  <!-- Mobile Navigation -->
  <div class="nav-toggle-open-wrapper toggle-dark">
    <?xml version="1.0" encoding="utf-8"?>
    <!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN" "https://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd">
    <svg version="1.1" xmlns="https://www.w3.org/2000/svg" xmlns:xlink="https://www.w3.org/1999/xlink" x="0px" y="0px" width="24px" height="18px" viewBox="0 0 24 18" enable-background="new 0 0 24 18" xml:space="preserve">
      <line fill="none" stroke-width="2" stroke-miterlimit="10" x1="0" y1="9" x2="24" y2="9"/>
      <line fill="none" stroke-width="2" stroke-miterlimit="10" x1="0" y1="1" x2="24" y2="1"/>
      <line fill="none" stroke-width="2" stroke-miterlimit="10" x1="0" y1="17" x2="24" y2="17"/>
    </svg>
  </div>
  <div class="nav-toggle-body-overlay"></div>
    <div class="toggled-nav-wrapper">
      <div class="nav-toggle-close-wrapper">
        <?xml version="1.0" encoding="utf-8"?>
        <!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN" "https://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd">
        <svg version="1.1" xmlns="https://www.w3.org/2000/svg" xmlns:xlink="https://www.w3.org/1999/xlink" x="0px" y="0px" width="18.385px" height="18.385px" viewBox="0 0 18.385 18.385" enable-background="new 0 0 18.385 18.385" xml:space="preserve">
          <line fill="none" stroke-width="2" stroke-miterlimit="10" x1="0.707" y1="17.678" x2="17.678" y2="0.707"/>
          <line fill="none" stroke-width="2" stroke-miterlimit="10" x1="0.707" y1="0.707" x2="17.678" y2="17.678"/>
        </svg>
      </div>
      <div class="internal-nav-links-wrapper">
        <a href="/" class="internal-link-wrapper"><div class="link-titles-wrapper"><h5>Home</h5></div><div class="internal-link-icon internal-link-icon-home"></div></a>
        <a href="/team" class="internal-link-wrapper"><div class="link-titles-wrapper"><h5>Team</h5></div><div class="internal-link-icon internal-link-icon-team"></div></a>
        <a href="/publications" class="internal-link-wrapper"><div class="link-titles-wrapper"><h5>Publications</h5></div><div class="internal-link-icon internal-link-icon-publications"></div></a>
        <a href="/projects" class="internal-link-wrapper"><div class="link-titles-wrapper"><h5>Projects</h5></div><div class="internal-link-icon internal-link-icon-research"></div></a>
        <a href="/news" class="internal-link-wrapper"><div class="link-titles-wrapper"><h5>News</h5></div><div class="internal-link-icon internal-link-icon-news"></div></a>
        <a href="/contact-us" class="internal-link-wrapper"><div class="link-titles-wrapper"><h5>Contact Us</h5></div><div class="internal-link-icon internal-link-icon-contact-us"></div></a>
      </div>
      <hr/>
      <div class="external-links-wrapper">
        <a href="https://scholar.google.com/citations?user=9PX9YjUAAAAJ&hl=en" target="_blank" class="external-link-wrapper"><h6>Google Scholar</h6><div class="external-link-icon external-link-icon-googlescholar"></div></a>
        <a href="mailto:ajaz.bhat@ubd.edu.bn" target="_blank" class="external-link-wrapper"><h6>Email</h6><div class="external-link-icon external-link-icon-email"></div></a>
        <a href="https://www.youtube.com/channel/UCbTav7pqgfIFCoH_ccnXPMw" target="_blank" class="external-link-wrapper"><h6>Youtube</h6><div class="external-link-icon external-link-icon-youtube"></div></a>
      </div>
    </div>
  
</nav>
<!-- End Navigation -->

<!-- Hero Section -->
<div class="container-1">
  <!-- Dynamic Project Slider Component -->

<div class="slider" data-interval="5000">
    
    
    
    
    <div id="causal-learning-robotics" class="slide">
        
        <img src="https://images.pexels.com/photos/17808485/pexels-photo-17808485.jpeg" alt="Causal Learning & Body Schema in Robotics" loading="lazy">
        <div class="slide-text">
            <h1><a href="/project/causal-learning-robotics/">Causal Learning & Body Schema in Robotics</a></h1>
            <p>This project focuses on how robots can abstract cause-effect relations from experience, enabling intuitive actions with unseen objects. By developing body schema models and causal learning algorithms, robots gain the ability to understand their physical capabilities and predict interaction outcomes, leading to more natural and effective manipulation skills.</p>
        </div>
    </div>
    
    <div id="knowledge-graph-completion" class="slide">
        
        <img src="https://images.pexels.com/photos/17808485/pexels-photo-17808485.jpeg" alt="Knowledge Graph Completion & AI-Recommender Systems" loading="lazy">
        <div class="slide-text">
            <h1><a href="/project/knowledge-graph-completion/">Knowledge Graph Completion & AI-Recommender Systems</a></h1>
            <p>Developed innovative models for predicting missing graph links in knowledge graphs, with applications spanning drug discovery, recommendation systems, and human resources. This research leverages advanced machine learning techniques to solve complex graph completion problems and has been recognized at top-tier conferences including ACL, NeurIPS, and ICML.</p>
        </div>
    </div>
    
    <div id="language-visual-exploration" class="slide">
        
        <img src="https://images.pexels.com/photos/17808485/pexels-photo-17808485.jpeg" alt="Language & Visual Exploration in Infants" loading="lazy">
        <div class="slide-text">
            <h1><a href="/project/language-visual-exploration/">Language & Visual Exploration in Infants</a></h1>
            <p>This project developed computational models explaining how babies learn language through visual exploration patterns. By studying the intersection of vision and language development, we created AI systems that mirror infant learning processes and match behavioral patterns observed in developmental psychology studies.</p>
        </div>
    </div>
    
    <div id="memory-based-reasoning" class="slide">
        
        <img src="https://images.pexels.com/photos/17808485/pexels-photo-17808485.jpeg" alt="Memory-Driven Reasoning in Robots" loading="lazy">
        <div class="slide-text">
            <h1><a href="/project/memory-based-reasoning/">Memory-Driven Reasoning in Robots</a></h1>
            <p>This project explores how robots can simulate past experiences to solve new problems creatively and efficiently. By developing memory-driven reasoning systems, robots can leverage historical interactions to adapt to novel situations, demonstrating enhanced problem-solving capabilities in both experimental settings and industrial multi-robot environments.</p>
        </div>
    </div>
    
    <div id="motor-control-cognition" class="slide">
        
        <img src="https://images.pexels.com/photos/17808485/pexels-photo-17808485.jpeg" alt="Motor Intelligence & Cognitive Control" loading="lazy">
        <div class="slide-text">
            <h1><a href="/project/motor-control-cognition/">Motor Intelligence & Cognitive Control</a></h1>
            <p>This project develops neural models that improve dexterity and tool use in complex manipulation tasks. By integrating cognitive control mechanisms with motor learning, robots achieve fast and adaptable motion capabilities. The research has been successfully applied to both humanoid robots like iCub and industrial robotic systems.</p>
        </div>
    </div>
    
    <div id="spatial-planning-collaboration" class="slide">
        
        <img src="https://images.pexels.com/photos/17808485/pexels-photo-17808485.jpeg" alt="Spatial Planning & Multi-Robot Collaboration" loading="lazy">
        <div class="slide-text">
            <h1><a href="/project/spatial-planning-collaboration/">Spatial Planning & Multi-Robot Collaboration</a></h1>
            <p>This project addresses how robots coordinate in shared spaces through dynamic planning and task negotiation. By developing sophisticated spatial planning algorithms and communication protocols, teams of robots can work together efficiently in complex environments, enabling scalable teamwork in real-world assembly and manufacturing scenarios.</p>
        </div>
    </div>
    
    <div id="word-learning-experiments" class="slide">
        
        <img src="https://images.pexels.com/photos/17808485/pexels-photo-17808485.jpeg" alt="Word Learning Experiments Across Ages" loading="lazy">
        <div class="slide-text">
            <h1><a href="/project/word-learning-experiments/">Word Learning Experiments Across Ages</a></h1>
            <p>This experimental study examined how children's attention patterns differ from adults during word learning tasks. The research revealed significant differences in attention mechanisms across age groups, challenging standard testing methodologies and supporting new computational models of language acquisition.</p>
        </div>
    </div>
    
</div>

<div>
     <button class="arrow left-arrow">&#10094;</button>
     <button class="arrow right-arrow">&#10095;</button>
</div>

<script>
  // Dynamic slider configuration
  const slider = document.querySelector('.slider');
  const slides = document.querySelectorAll('.slide');
  const leftArrow = document.querySelector('.left-arrow');
  const rightArrow = document.querySelector('.right-arrow');
  
  // Get dynamic interval from data attribute (no hardcoded fallback)
  const sliderInterval = parseInt(slider.dataset.interval);
  let index = 0;
  let interval;

  function goToSlide(i) {
    index = (i + slides.length) % slides.length;
    slider.scrollTo({
      left: slides[index].offsetLeft,
      behavior: 'smooth'
    });
    resetInterval();
  }

  function resetInterval() {
    clearInterval(interval);
    interval = setInterval(() => {
      index = (index + 1) % slides.length;
      slider.scrollTo({
        left: slides[index].offsetLeft,
        behavior: 'smooth'
      });
    }, sliderInterval);
  }

  // Initialize slider if elements exist
  if (slider && slides.length > 0) {
    leftArrow?.addEventListener('click', () => goToSlide(index - 1));
    rightArrow?.addEventListener('click', () => goToSlide(index + 1));
    resetInterval();
  }
</script>
  <!-- Navigation Arrows Component -->
<div>
    <a href="#container-3" class="int-arrows-body">
        <div class="int-arrow"></div>
        <div class="int-arrow"></div>
    </a>
</div>
</div>

<!-- Latest Lab Content -->
<!-- Lab Content Slider - Combined publications and news -->
<div id="container-3" class="container-3">
  <!-- Page Header Component -->
<div class="header-wrapper">
  <h1 class="header">Latest from the Lab</h1>
  
</div>
  <div class="scroller">
    <div class="publications-content-wrapper">
      <!-- Dynamic Content Mixer - Configuration-driven mixed content generation -->



<!-- Dynamic configuration variables -->





<!-- Latest Publications (dynamic limit) -->





<!-- Latest News Posts (dynamic limit) -->


<!-- Shuffle and Display Content (dynamic limit) -->


  
  
  
  
  
  
  
  
  <div class="content-box" data-href="/talks/research/2025/03/15/ai-robotics-talk-ubd/" data-type="news">
    <div class="content-type-badge news-badge">
      News
    </div>
    <div class="content-box-text">
      <h1>AI & Robotics Talk: 'From Code to Creation' at UBD</h1>
      <div class="image-box">
        <img src="/assets/images/news/robotics-talk.jpeg" alt="AI & Robotics Talk: 'From Code to Creation' at UBD">
      </div>
      <p>Assistant Professor Dr Ajaz Ahmad Bhat delivered an insightful talk titled ‘From Code to Creation’ at Universiti Brunei Darussalam.
</p>
    </div>
    <div class="read-more">
      <a href="/talks/research/2025/03/15/ai-robotics-talk-ubd/">Read more →</a>
    </div>
    <div class="overlay"></div>
  </div>

  
  
  
  
  
  
  
  
  <div class="content-box" data-href="/research/robotics/ai/2020/04/15/creative-ai-research/" data-type="news">
    <div class="content-type-badge news-badge">
      News
    </div>
    <div class="content-box-text">
      <h1>Creative AI Research: Problem-Solving in Robots</h1>
      <div class="image-box">
        <img src="/assets/images/news/creative-ai.jpeg" alt="Creative AI Research: Problem-Solving in Robots">
      </div>
      <p>Paper submitted on Creative Problem-Solving in Robots using Constructive Episodic Simulations. This groundbreaking research explores how robots can develop creative...</p>
    </div>
    <div class="read-more">
      <a href="/research/robotics/ai/2020/04/15/creative-ai-research/">Read more →</a>
    </div>
    <div class="overlay"></div>
  </div>

  
  
  
  
  
  
  
  
  <div class="content-box" data-href="/conferences/committee/2025/01/01/icitda-committee-member/" data-type="news">
    <div class="content-type-badge news-badge">
      News
    </div>
    <div class="content-box-text">
      <h1>Conference Committee Member for ICITDA 2025</h1>
      <div class="image-box">
        <img src="/assets/images/news/conference.jpeg" alt="Conference Committee Member for ICITDA 2025">
      </div>
      <p>Dr. Ajaz Bhat serves as a committee member for ICITDA 2025 (International Conference on Information Technology and Data Analytics), contributing...</p>
    </div>
    <div class="read-more">
      <a href="/conferences/committee/2025/01/01/icitda-committee-member/">Read more →</a>
    </div>
    <div class="overlay"></div>
  </div>

  
  
  
  
  
  
  
  
  <div class="content-box" data-href="/conference/research/causal-learning/2020/01/15/iclr-causal-learning-aesop/" data-type="news">
    <div class="content-type-badge news-badge">
      News
    </div>
    <div class="content-box-text">
      <h1>ICLR 2020: Causal Learning in Aesop's Fable Experiment</h1>
      <div class="image-box">
        <img src="/assets/images/news/causal-learning.jpeg" alt="ICLR 2020: Causal Learning in Aesop's Fable Experiment">
      </div>
      <p>Paper accepted at ICLR 2020: “A Causal Learning by a Robot with Semantic-Episodic Memory in an Aesop’s Fable Experiment.” This...</p>
    </div>
    <div class="read-more">
      <a href="/conference/research/causal-learning/2020/01/15/iclr-causal-learning-aesop/">Read more →</a>
    </div>
    <div class="overlay"></div>
  </div>

  
  
  
  
  
  
  
  
  <div class="content-box" data-href="/vacancies/opportunities/2025/09/09/open-vacancies-lab-positions/" data-type="news">
    <div class="content-type-badge news-badge">
      News
    </div>
    <div class="content-box-text">
      <h1>Open Vacancies - Master's and PhD Positions Available</h1>
      <div class="image-box">
        <img src="/assets/images/news/lab-vacancies.jpeg" alt="Open Vacancies - Master's and PhD Positions Available">
      </div>
      <p>Vacancies are available for local and international candidates interested in pursuing a Master’s or PhD degree in our lab. Our...</p>
    </div>
    <div class="read-more">
      <a href="/vacancies/opportunities/2025/09/09/open-vacancies-lab-positions/">Read more →</a>
    </div>
    <div class="overlay"></div>
  </div>

  
  
  
  
  
  
  
  
  <div class="content-box" data-href="/publication/2024-2-formal-theories-neural-process-visual-exploration-word-learning/" data-type="publication">
    <div class="content-type-badge publication-badge">
      Publication
    </div>
    <div class="content-box-text">
      <h1>Formal theories clarify the complex: Generalizing a neural process account of the interaction of visual exploration and word learning in infancy</h1>
      <div class="image-box">
        <img src="https://images.pexels.com/photos/17808485/pexels-photo-17808485.jpeg" alt="Formal theories clarify the complex: Generalizing a neural process account of the interaction of visual exploration and word learning in infancy">
      </div>
      <p>Visual exploration and auditory processing interact to support object discrimination, categorization, and early word learning. To clarify their complex, multi‐timescale interactions, we generalize a formal neural process model of word learning to simulate two infant studies of label‐driven novelty preference (9–22 months). Simulations explain label effects on looking and mutual‐exclusivity responses. We discuss criteria for formal theories and their integration with empirical paradigms.</p>
    </div>
    <div class="read-more">
      <a href="/publication/2024-2-formal-theories-neural-process-visual-exploration-word-learning/">Read more →</a>
    </div>
    <div class="overlay"></div>
  </div>

  
  
  
  
  
  
  
  
  <div class="content-box" data-href="/publication/2024-3-similarity-object-properties-cross-situational-word-learning/" data-type="publication">
    <div class="content-type-badge publication-badge">
      Publication
    </div>
    <div class="content-box-text">
      <h1>Similarity in object properties supports cross-situational word learning: Predictions from a dynamic neural model confirmed</h1>
      <div class="image-box">
        <img src="https://images.pexels.com/photos/17808485/pexels-photo-17808485.jpeg" alt="Similarity in object properties supports cross-situational word learning: Predictions from a dynamic neural model confirmed">
      </div>
      <p>Context manipulations reveal that similarity in object properties can counterintuitively facilitate word learning. Using the WOLVES dynamic field model, we simulated CSWL under two conditions: 'NEAR' (objects metrically similar) and 'FAR' (objects distinct). WOLVES predicted superior learning in NEAR trials. An adult behavioral experiment confirmed this novel prediction, demonstrating that contextual similarity enhances cross‐situational word mapping.</p>
    </div>
    <div class="read-more">
      <a href="/publication/2024-3-similarity-object-properties-cross-situational-word-learning/">Read more →</a>
    </div>
    <div class="overlay"></div>
  </div>

  
  
  
  
  
  
  
  
  <div class="content-box" data-href="/publication/2025-1-kg-edas-meta-metric-framework-knowledge-graph-evaluation/" data-type="publication">
    <div class="content-type-badge publication-badge">
      Publication
    </div>
    <div class="content-box-text">
      <h1>KG-EDAS: A Meta-Metric Framework for Evaluating Knowledge Graph Completion Models</h1>
      <div class="image-box">
        <img src="https://images.pexels.com/photos/590022/pexels-photo-590022.jpeg" alt="KG-EDAS: A Meta-Metric Framework for Evaluating Knowledge Graph Completion Models">
      </div>
      <p>Current evaluation practices for knowledge graph completion models lack standardization and often fail to capture model capabilities comprehensively. We introduce KG-EDAS (Knowledge Graph Evaluation through Data-Aware Scoring), a meta-metric framework that provides more robust and interpretable evaluation of KGC models. Our framework addresses key limitations in existing evaluation protocols.</p>
    </div>
    <div class="read-more">
      <a href="/publication/2025-1-kg-edas-meta-metric-framework-knowledge-graph-evaluation/">Read more →</a>
    </div>
    <div class="overlay"></div>
  </div>

  
  
  
  
  
  
  
  
  <div class="content-box" data-href="/publication/2025-2-muco-kgc-multi-context-knowledge-graph-completion/" data-type="publication">
    <div class="content-type-badge publication-badge">
      Publication
    </div>
    <div class="content-box-text">
      <h1>MuCo-KGC: Multi-Context-Aware Knowledge Graph Completion</h1>
      <div class="image-box">
        <img src="https://images.pexels.com/photos/8386440/pexels-photo-8386440.jpeg" alt="MuCo-KGC: Multi-Context-Aware Knowledge Graph Completion">
      </div>
      <p>Traditional knowledge graph completion methods often ignore the rich contextual information available in multi-relational graphs. We propose MuCo-KGC, a multi-context-aware approach that leverages diverse contextual signals to improve link prediction performance. Our method achieves state-of-the-art results on several benchmarks while maintaining computational efficiency.</p>
    </div>
    <div class="read-more">
      <a href="/publication/2025-2-muco-kgc-multi-context-knowledge-graph-completion/">Read more →</a>
    </div>
    <div class="overlay"></div>
  </div>

  
  
  
  
  
  
  
  
  <div class="content-box" data-href="/publication/2025-3-mucos-drug-target-discovery-knowledge-graphs/" data-type="publication">
    <div class="content-type-badge publication-badge">
      Publication
    </div>
    <div class="content-box-text">
      <h1>MuCoS: Efficient Drug Target Discovery via Multi Context Aware Sampling in Knowledge Graphs</h1>
      <div class="image-box">
        <img src="https://images.pexels.com/photos/3825577/pexels-photo-3825577.jpeg" alt="MuCoS: Efficient Drug Target Discovery via Multi Context Aware Sampling in Knowledge Graphs">
      </div>
      <p>Knowledge graphs (KGs) have emerged as powerful tools for drug discovery, but existing methods often fail to capture the multi-contextual nature of biomedical relationships. We introduce MuCoS (Multi Context Aware Sampling), a novel approach that efficiently discovers drug targets by sampling diverse contextual neighborhoods in biomedical KGs. Our method significantly improves target identification accuracy while reducing computational overhead.</p>
    </div>
    <div class="read-more">
      <a href="/publication/2025-3-mucos-drug-target-discovery-knowledge-graphs/">Read more →</a>
    </div>
    <div class="overlay"></div>
  </div>

    </div>
  </div>
</div>

<footer class="lab-footer">
  <div class="footer-left">
    <h4>© Dr. Ajaz Ahmad Bhat</h4>
  </div>
  <div class="footer-right">
    <a href="/contact-us" class="">Visit Us</a>
    <address>
      <p class="">School of Digital Science</p>
      <p class="">Room 2.48 2nd Floor APB Building, Universiti Brunei Darussalam, Jalan Tungku Link, BE1410</p>
      <p class="">Brunei Darussalam</p>
    </address>
  </div>
</footer>

<!-- Consolidated Site JavaScript -->
<script src="/assets/js/jquery-3.7.1.min.js"></script>
<script>
// === DYNAMIC SITE FUNCTIONALITY MODULE ===
// Configuration-driven JavaScript with no hardcoded values

const SiteFeatures = {
  
  // Dynamic configuration from Jekyll data
  config: {
    scrollDuration: 800,
    fadeDuration: 300,
    scrollOffset: 100,
    hoverScale: 1.02,
    transitionSpeed: '0.3s',
    lazyLoading: true,
    searchDelay: 300,
    minSearchLength: 2
  },
  
  // Initialize all site features
  init() {
    this.initScrollerAnimation();
    this.initClickableCards();
    this.initNavigation();
    this.initSmoothScroll();
    this.initDynamicInteractions();
  },

  // Scroller animation for content cards
  initScrollerAnimation() {
    const scrollers = document.querySelectorAll(".scroller");
    
    // Check for reduced motion preference
    if (window.matchMedia("(prefers-reduced-motion: reduce)").matches) return;
    
    scrollers.forEach((scroller) => {
      scroller.setAttribute("data-animated", true);
      
      const scrollerInner = scroller.querySelector(".publications-content-wrapper");
      if (!scrollerInner) return;
      
      const scrollerContent = Array.from(scrollerInner.children);
      
      // Clone items for infinite scroll effect
      scrollerContent.forEach((item) => {
        const duplicatedItem = item.cloneNode(true);
        duplicatedItem.setAttribute("aria-hidden", true);
        scrollerInner.appendChild(duplicatedItem);
      });
    });
  },

  // Make content cards clickable
  initClickableCards() {
    document.querySelectorAll('.content-box[data-href], .news-wrapper[data-href]').forEach(el => {
      el.style.cursor = 'pointer';
      el.addEventListener('click', (e) => {
        // Don't trigger navigation if clicking on links
        if (e.target.tagName === 'A') return;
        
        const url = el.dataset.href;
        if (url) window.location.href = url;
      });
    });
  },

  // Navigation functionality
  initNavigation() {
    // Navigation toggle functionality
    $('.toggled-nav-wrapper').on('click', function(e) {
      e.stopPropagation();
    });

    $('.nav-toggle-open-wrapper, .nav-toggle-close-wrapper, header .nav-toggle-body-overlay').on('click', function() {
      $('html').toggleClass('nav-open');
    });
  },

  // Dynamic smooth scroll functionality
  initSmoothScroll() {
    const scrollDuration = this.config.scrollDuration;
    $('a[href*="#"]:not([href="#"])').click(function() {
      if (location.pathname.replace(/^\//, '') === this.pathname.replace(/^\//, '') && location.hostname === this.hostname) {
        var target = $(this.hash);
        target = target.length ? target : $('[name=' + this.hash.slice(1) + ']');
        if (target.length) {
          $('html, body').animate({
            scrollTop: target.offset().top
          }, scrollDuration);
          return false;
        }
      }
    });
  },

  // Dynamic interaction enhancements
  initDynamicInteractions() {
    // Apply dynamic hover effects if configured
    if (this.config.hoverScale !== 1) {
      const scaleValue = this.config.hoverScale;
      $('[data-hover-scale]').each(function() {
        $(this).css('transition', `transform ${SiteFeatures.config.transitionSpeed} ease`);
        $(this).hover(
          function() { $(this).css('transform', `scale(${scaleValue})`); },
          function() { $(this).css('transform', 'scale(1)'); }
        );
      });
    }
    
    // Dynamic lazy loading if enabled
    if (this.config.lazyLoading && 'IntersectionObserver' in window) {
      const imageObserver = new IntersectionObserver((entries, observer) => {
        entries.forEach(entry => {
          if (entry.isIntersecting) {
            const img = entry.target;
            img.src = img.dataset.src;
            img.classList.remove('lazy');
            observer.unobserve(img);
          }
        });
      });
      document.querySelectorAll('img[data-src]').forEach(img => imageObserver.observe(img));
    }
  }
};

// Initialize when DOM is ready
$(document).ready(() => SiteFeatures.init());
</script>
        <script type="text/javascript" src="/assets/js/jquery-3.7.1.min.js"></script>
    </body>
</html>